{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00552366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.protocol import RawValueProtocol\n",
    "import json\n",
    "import operator\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "\n",
    "\n",
    "# Load stopwords\n",
    "with open(\"countoutput.txt\", \"r\") as count_file:\n",
    "    for line in count_file:\n",
    "        parts = line.strip().split(\"\\t\")  # Split the line on the tab character\n",
    "        if parts[0] == \"null\":  # Check if the first part is 'null'\n",
    "            DOCS_LENGTH = int(parts[1])\n",
    "with open(\"stopwords.txt\") as stopwords_file:\n",
    "    STOPWORDS = set(line.strip() for line in stopwords_file)\n",
    "    \n",
    "\n",
    "class Chi(MRJob):\n",
    "    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper,\n",
    "                   combiner=self.combiner),\n",
    "            MRStep (reducer= self.reducer2),\n",
    "            MRStep (mapper= self.mapper2),\n",
    "            MRStep (reducer= self.reducer3),\n",
    "            MRStep (mapper= self.mapper4)\n",
    "    \n",
    "    def configure_args(self):\n",
    "        super(Chi, self).configure_args()\n",
    "        self.add_file_arg('--stopwords', help='stopwords.txt', default='stopwords.txt')\n",
    "\n",
    "    def mapper_init(self):\n",
    "        with open(self.options.stopwords, 'r') as file:\n",
    "            self.STOPWORDS = set(line.strip() for line in file)\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "    \n",
    "        OUTPUT_PROTOCOL = RawValueProtocol\n",
    "\n",
    "    \n",
    "        ]\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        # Load the JSON object\n",
    "        json_line = json.loads(line)\n",
    "\n",
    "        # Extract the review and category\n",
    "        review = json_line.get('reviewText', '')\n",
    "        category = json_line.get('category', '')\n",
    "        # Tokenise review text\n",
    "        review_tok = re.findall('[A-Za-z]+', review)\n",
    "        \n",
    "        # Filter out stopwords and words with only one character\n",
    "        for term in review_tok:\n",
    "            # case-fold the word\n",
    "            term = term.lower()\n",
    "            if term in STOPWORDS: # skip stopwords\n",
    "                continue\n",
    "                \n",
    "            yield (category,term), 1 # to count how many TERMS we have => gives us A\n",
    "            \n",
    "\n",
    "    def combiner(self, key, counts): # reduce/group by (category, term)_sum of each unique category,term\n",
    "        category, term = key\n",
    "        s = sum(counts)\n",
    "        yield term, (category,s)\n",
    "    \n",
    "    def reducer2 (self, term, values):   \n",
    "        yield term, list(values)\n",
    "    \n",
    "    def mapper2(self, term, value_list):\n",
    "   \n",
    "        values_dict = {val[0]:  val[1] for val in value_list}\n",
    "        new_dict={} # dic--> category: A,B\n",
    "        for category, value in values_dict.items():\n",
    "            new_dict[category]=[value, sum(values_dict.values())-value] \n",
    "                # category: { value=A, B=sum(values_dict.values())-A}\n",
    "        for category, value in new_dict.items():\n",
    "            yield category, (term,value[0],value[1]) # emit category, term, A, B\n",
    "    \n",
    "  \n",
    "    def reducer3 (self, category, values):\n",
    "        yield category, list(values) # reduce by category to receive list of lists\n",
    "        \n",
    "    def mapper4(self, category, value_list):\n",
    "        values_bigdict_temp = {val[0]: val[1] for val in value_list}  # create dict to easier extract sum pro category\n",
    "        sum_pro_category = sum(values_bigdict_temp.values())  # calculate the sum of docs pro category\n",
    "        values_bigdict_withCN = {val[0]: [val[1], val[2], sum_pro_category - val[1], DOCS_LENGTH] for val in value_list}\n",
    "        final_dict = {}\n",
    "        for key, val in values_bigdict_withCN.items():\n",
    "            A = val[0]\n",
    "            B = val[1]\n",
    "            C = val[2]\n",
    "            N = val[3]\n",
    "            D = N - A - B - C\n",
    "            top = N * (A * D - B * C) ** 2\n",
    "            bottom = (A + B) * (A + C) * (B + D) * (C + D)\n",
    "            if bottom == 0 or math.isinf(bottom) or math.isnan(bottom) or top == 0 or math.isinf(top) or math.isnan(top):\n",
    "                final_dict[key] = 0\n",
    "            else:\n",
    "                final_dict[key] = top / bottom\n",
    "\n",
    "    # Emit category results with chi-squared values\n",
    "        sorted_terms = sorted(final_dict.items(), key=operator.itemgetter(1), reverse=True)[0:75]\n",
    "        \n",
    "        # Construct the output string in the desired format with category enclosed in <>\n",
    "        result = f\"<{category}> \" + \" \".join(f\"{term}:{value}\" for term, value in sorted_terms)\n",
    "        \n",
    "        yield None, result\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Chi.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
